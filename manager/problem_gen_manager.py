import random
from dataclasses import dataclass, field
from typing import Generator, Dict, Optional, Literal, TypedDict, List, Any, Set
import os

from tqdm.auto import tqdm

from pathlib import Path
import pandas as pd
from datasets import Dataset, DatasetDict, load_dataset

from client.concrete.math_phys_problem_gen import MathPhysProblemGenerator

from util.file_tools import JsonHandler, JsonlHandler
from util.hub_push_tools import HuggingHubConfig, push_to_hub

from logging import getLogger, NullHandler

logger = getLogger(__name__)
logger.addHandler(NullHandler())

SUBJECT = ["Math", "Physics"]

SUB_FIELD_MATH = [
    "Algebra",
    "Combinatorics",
    "Geometry",
    "Number Theory"
]

SUB_FIELD_PHYS = [
    "atomic",
    "electro",
    "mechanics",
    "optics",
    "quantum",
    "statistics",
]


@dataclass
class MathPhysGeneratorConfig:
    output_dir: str  # Directory to store generated files (*.jsonl)
    output_file_decoration: str = "math_phys_problem"  # String to append to generated file names
    batch_size: int = 1  # Number of items to process and save in each batch (usually 1)
    num_of_few_shot: int = 3  # Number of few-shot examples to provide when generating problems
    num_of_generate: int = 3  # Total number of problems to generate (stop when reached)


'''

'./data/seed/olympiadBench_TO_maths_en_COMP.jsonl'  1177
"Combinatorics", "Algebra", "Number Theory", "Geometry"


'./data/seed/PHYSICS_TO.jsonl'  999
"atomic", "electro", "mechanics", "optics", "quantum", "statistics"
'''


def check_sentence_establishment(response: str) -> bool:
    """
    Check if the LLM's response forms a valid sentence
    (Simple check based on word count: more than 15 words)

    Parameters
    ----------
    response
        The response generated by the LLM

    Returns
    -------
        Boolean indicating whether the response forms a valid sentence
    """
    if response:
        is_sentence = len(response.split()) > 15
        return True if is_sentence else False
    else:
        return False


class FieldFilteredDataPicker:
    def __init__(
            self,
            jsonl_file: str = './data/seed/olympiadBench_TO_maths_en_COMP.jsonl',
            target_column: str = "subfield",
    ):
        self._target_column = target_column

        df = pd.read_json(jsonl_file, lines=True)
        self._seed_keys = {'id', 'question', 'solution', 'answer', 'subject', 'subfield'}

        missing_keys = self._seed_keys - set(df.columns.tolist())
        if missing_keys:
            error_msg = f"Key required for dictionary data is missing.\nMissing keys: {missing_keys}"
            logger.error(error_msg)
            raise ValueError(error_msg)

        # print(len(df.index))
        # target_columnの値ごとの個数をカウント
        counts = df[self._target_column].value_counts()
        # 10個に満たないものは除外
        valid_values = counts[counts > 10].index
        self._df = df[df[self._target_column].isin(valid_values)]

        # print(len(self._df))
        # unique_keys = self._df[self._target_column].unique().tolist()
        # print(len(unique_keys))
        # for i in unique_keys:
        #     print(f'"{i}",')
        # assert False, ""

    def get_random_data(self, num_of_sample: int, field_value: str) -> List[Dict]:
        """
        Randomly extract the specified number of data samples

        Returns
           List of extracted data in dictionary format

        """

        subject_df = self._df

        # subfieldカラムが指定された値であるデータを抽出
        field_df = subject_df[subject_df[self._target_column] == field_value].copy()

        # numpy.ndarrayを要素として含むカラムを文字列に変換
        for col in field_df.columns:
            if field_df[col].dtype == 'object':
                try:
                    field_df[col] = field_df[col].astype(str)
                except:
                    pass  # Skip if conversion fails

        field_df = field_df.drop_duplicates()
        # DataFrameを辞書のリストに変換
        data_list = field_df.to_dict('records')
        random.shuffle(data_list)
        sampled_data = data_list[:num_of_sample]
        return sampled_data


class MathPhysGeneratorManager(object):
    def __init__(
            self,
            model_name: str,
            seed_math_jsonl: str,
            seed_phys_jsonl: str,
    ):
        """

        Parameters
        ----------
        main_llm
            The LLM used for generation
        batch_size
            Number of items to process and save at once
        """
        self._model = model_name
        self._seed_picker_math = FieldFilteredDataPicker(seed_math_jsonl, target_column="subfield")
        self._seed_picker_phys = FieldFilteredDataPicker(seed_phys_jsonl, target_column="subfield")
    
    def __call__(
            self,
            manager_cfg: MathPhysGeneratorConfig,
            hf_cfg: Optional[HuggingHubConfig] = None,
    ) -> None:
        self.file_handling(manager_cfg, hf_cfg)

    def problem_creator(self, task_seeds: List[Dict]) -> List[Dict]:
        """
        Parameters
        ----------
        task_seeds
            "id" : ID number assigned after generation
            "few-shot": few-shot examples randomly generated by seed_creator() from jsonl files
        Returns
        -------
    
        """
        outputs = []

        for seed in task_seeds:
            id = seed['id']
            few_shots = seed['few-shot']

            instruction = {
                "few_shot_1": few_shots[0],
                "few_shot_2": few_shots[1],
            }

            few_shots_num = len(few_shots[0])
            math_gen = MathPhysProblemGenerator(self._model, few_shot_num=few_shots_num)
            result = math_gen.parse(instruction)

            if result and check_sentence_establishment(result['Final_Rewritten_Problem']):
                gen_skill_data = dict(
                    id=int(id),
                    final_score=result['Final_Rewritten_Score'],
                    question=result['Final_Rewritten_Problem'],
                    problem_draft=result['Problem_Draft'],
                    element_idendified=result['Elements_Identified'],
                    plan=result['Plan'],
                    rewritten_problem=result['Rewritten_Problem'],
                )

                outputs.append(gen_skill_data)
        return outputs

    def seed_creator(
            self,
            manager_cfg: MathPhysGeneratorConfig
    ) -> List[str]:
        """
        Create two stringified few-shot strings and output as List[str]
        The first few-shot string -> <skill_1>
        The second few-shot string -> <skill_2>
        """
        num_of_few_shot = manager_cfg.num_of_few_shot
    
        math_field = random.sample(SUB_FIELD_MATH, 1)
        phys_field = random.sample(SUB_FIELD_PHYS, 1)
    
        # math_phys = [math_field, phys_field]
        math_phys_seed_list = [
            {"skill": math_field[0], "seed": self._seed_picker_math.get_random_data(num_of_few_shot, math_field[0])},
            {"skill": phys_field[0], "seed": self._seed_picker_phys.get_random_data(num_of_few_shot, phys_field[0])},
        ]
    
        few_shot_list = []
    
        for seed in math_phys_seed_list:
            skill = seed['skill']
    
            # Extract only the columns to be used
            seeds = [{"problem": d['question'], "solution": d['solution'], "answer": d['answer']} for d in
                     seed['seed']]
    
            few_shot_list.append(MathPhysProblemGenerator.encode_few_shot_prompt(skill, seeds))
    
        return few_shot_list

    def file_handling(
            self,
            manager_cfg: MathPhysGeneratorConfig,
            hf_cfg: Optional[HuggingHubConfig]
    ):
        out_suffix = '.jsonl'
        output_base_dir = manager_cfg.output_dir
        output_file_decoration = manager_cfg.output_file_decoration
        num_of_generate = manager_cfg.num_of_generate
        batch_size = manager_cfg.batch_size

        output_file_name = output_file_decoration + out_suffix
        fp_output_file = Path(output_base_dir + output_file_name)

        if not fp_output_file.parent.exists():
            fp_output_file.parent.mkdir(parents=True, exist_ok=True)

        # Tool for reading and writing jsonl files
        jlh = JsonlHandler()

        # 途中から再開する場合
        if os.path.isfile(fp_output_file):
            gen_objects = jlh.read(str(fp_output_file))
            current_count = len(gen_objects) if gen_objects else 0
        else:
            gen_objects = []
            current_count = 0

        # Initialize progress bar
        pbar = tqdm(
            total=num_of_generate,
            initial=current_count,
            desc="Generation Progress",
        )

        while current_count < num_of_generate:
            def batch_processor(start: int, b_size: int):
                seed_data_list = [{"id": i, "few-shot": self.seed_creator(manager_cfg)} for i in
                                  range(start, start + b_size)]
                yield self.problem_creator(seed_data_list)

            for processed in batch_processor(current_count + 1, batch_size):
                if processed:
                    gen_objects.extend(processed)
                    jlh.write(gen_objects, str(fp_output_file))

            new_count = len(gen_objects)

            pbar.update(new_count - current_count)
            current_count = new_count

            if current_count >= num_of_generate:
                break

        pbar.close()

        # Push to Huggingface
        if hf_cfg is not None and hf_cfg.repo_id:
            dataset = Dataset.from_pandas(pd.read_json(fp_output_file, lines=True))
            dataset_dict = DatasetDict(
                {"train": dataset},
            )
            push_to_hub(dataset_dict, hf_cfg)


if __name__ == "__main__":
    """
    python -m manager.problem_gen_manager
    """

    # def fix_seed(seed):
    #     random.seed(seed)
    #     np.random.seed(seed)
    #
    #
    # SEED = 46
    # fix_seed(SEED)

    from logging import DEBUG, INFO, WARNING, ERROR, basicConfig

    # basicConfig(level=WARNING)
    basicConfig(level=INFO)

    # model_name="deepseek/deepseek-r1:free"
    model_name = "deepseek/deepseek-r1-0528:free"
    # model_name="deepseek/deepseek-chat-v3-0324:free"
    # model_name="deepseek/deepseek-r1-0528"
    # model_name="deepseek/deepseek-chat-v3-0324"

    math_file = './data/seed/olympiadBench_TO_maths_en_COMP.jsonl'
    phys_file = './data/seed/PHYSICS_TO.jsonl'

    # math_pk = FieldFilteredDataPicker(math_file)
    # print(math_pk.get_random_data(1, "Combinatorics"))

    # phys_pk = FieldFilteredDataPicker(phys_file)
    # print(phys_pk.get_random_data(1, "atomic"))

    pgm = MathPhysGeneratorManager(
        model_name=model_name,
        seed_math_jsonl=math_file,
        seed_phys_jsonl=phys_file,
    )

    test_cfg = dict(
        output_dir='./data/problem/',
        output_file_decoration="math_phys_problem_v1.0",
        num_of_generate=1000,
        # num_of_generate=415,
        batch_size=1,
        num_of_few_shot=3,
    )

    data_config = MathPhysGeneratorConfig(**test_cfg)
    # pgm(data_config)

    from util.hub_push_tools import HuggingHubConfig, push_to_hub

    # Create Huggingface config file (do not push if values are not specified)
    hf_repo_id = "tarona/MathXPhys_scored_v1"
    hf_config_name ="OB_PHYS_problem"

    hf_cfg = HuggingHubConfig(repo_id=hf_repo_id, config_name=hf_config_name)
    pgm(data_config, hf_cfg)
